{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3772, 30)\n",
      "(3772, 29)\n",
      "(3772, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Classification of thyroid \n",
    "using deep learning (Keras)\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def extract_data(path):\n",
    "    data_frame = pd.read_csv(path, sep=\"\\t\")\n",
    "    return data_frame\n",
    "\n",
    "def create_features_target(data_frame):\n",
    "    target = data_frame[[\"target\"]]\n",
    "    features = data_frame.drop(\"target\", axis=1)\n",
    "    return features, target\n",
    "\n",
    "d_frame = extract_data(\"data/allbp.tsv\")\n",
    "print(d_frame.shape)\n",
    "data_features, data_target = create_features_target(d_frame)\n",
    "data_features = data_features\n",
    "print(data_features.shape)\n",
    "print(data_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2527, 29)\n",
      "(2527, 1)\n",
      "(1245, 29)\n",
      "(1245, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split\n",
    "data_features_train, data_features_test, data_target_train, data_target_test = train_test_split(data_features, \n",
    "                                                                                                data_target, test_size=0.33, random_state=42)\n",
    "\n",
    "print(data_features_train.shape)\n",
    "print(data_target_train.shape)\n",
    "print(data_features_test.shape)\n",
    "print(data_target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "import csv\n",
    "import pandas as pd\n",
    "import json\n",
    "import h5py\n",
    "\n",
    "# machine learning library\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Input\n",
    "from keras.layers.core import Dropout, Activation, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    output_units = 3\n",
    "    loss_type = 'categorical_crossentropy'\n",
    "    train_X, train_y, test_X, test_y = self.load_data()\n",
    "    inputs = Input(shape=(dimensions,))\n",
    "    x = Dense(int(params[\"hidden_units\"]), activation=params[\"hidden_activation\"])(inputs)\n",
    "    x = Dropout(params[\"dropout\"])(x)\n",
    "    x = Dense(int(params[\"hidden_units\"]), activation=params[\"hidden_activation\"])(x)\n",
    "    x = Dropout(params[\"dropout\"])(x)\n",
    "    predictions = Dense(output_units, activation=params[\"output_activation\"])(x)\n",
    "    # assign the inputs and output to the model\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    # create an optimizer object\n",
    "    optimizer = Adam(lr=params[\"learning_rate\"])\n",
    "    # add optimizer and loss type to the model\n",
    "    model.compile(optimizer=optimizer, loss=loss_type)\n",
    "    model.summary()\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
    "    # train the model using the training data and compute error on validation data\n",
    "    model_fit = model.fit(train_X, train_y, validation_data=(test_X, test_y), epochs=self.n_epochs, batch_size=int(params[\"batch_size\"]), callbacks=[early_stopping])\n",
    "    # predict on test data using trained model\n",
    "    prediction = model.predict(test_X)\n",
    "    return {'loss': model_fit.history[\"val_loss\"][-1], 'status': STATUS_OK, 'model': model}\n",
    "\n",
    "# set initial ranges for parameters\n",
    "max_evals = 30\n",
    "batch_size = [30, 250]\n",
    "hidden_activation = ['tanh', 'relu', 'elu', 'sigmoid']\n",
    "hidden_units = [30, 250]\n",
    "\n",
    "hyper_params = {\n",
    "    \"batch_size\": hp.quniform(\"batch_size\", batch_size[0], batch_size[1], 1),\n",
    "    \"hidden_units\": hp.quniform(\"hidden_units\", hidden_units[0], hidden_units[1], 1),\n",
    "    \"learning_rate\": hp.loguniform(\"learning_rate\", np.log(1e-4), np.log(1e-2)),\n",
    "    \"hidden_activation\": hp.choice(\"hidden_activation\", hidden_activation),\n",
    "    \"output_activation\": hp.choice(\"output_activation\", hidden_activation),\n",
    "    \"dropout\": hp.uniform(\"dropout\", 0.0, 0.5)\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "best_parameters = fmin(create_model, hyper_params, trials=trials, algo=tpe.suggest, max_evals=max_evals)\n",
    "sorted_results = sorted(trials.results, key=lambda i: i['loss'])\n",
    "apply_nn.save_model(sorted_results[0])\n",
    "\n",
    "best_model_params = dict()\n",
    "print(best_parameters)\n",
    "for item in best_parameters:\n",
    "    item_val = best_parameters[item]\n",
    "    if item == 'hidden_activation':\n",
    "        best_model_params[item] = hidden_activation[item_val]\n",
    "    elif item == 'output_activation':\n",
    "        best_model_params[item] = hidden_activation[item_val]\n",
    "    else:\n",
    "        best_model_params[item] = item_val\n",
    "print(best_model_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
